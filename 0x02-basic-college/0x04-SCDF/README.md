# SCDF

## **ðŸ“Œ 1. Introduction to Spring Cloud Data Flow (SCDF)**
ðŸ”¹ **What is SCDF?**  
SCDF is a **lightweight, cloud-native framework** that orchestrates both **batch** and **streaming** workloads using Spring technologies.  

ðŸ”¹ **Key Features for Spring Batch**  
- **Job Orchestration** â€“ Define and schedule batch jobs  
- **Monitoring & Logging** â€“ Track job executions & view logs  
- **Scaling & Distributed Execution** â€“ Run jobs across multiple instances  
- **REST API & UI** â€“ Control batch jobs via API and dashboard  

ðŸ”¹ **SCDF Components**  
- **Spring Cloud Data Flow Server** â€“ The core SCDF server managing jobs  
- **Spring Cloud Skipper** â€“ Handles deployment updates  
- **Task Launcher** â€“ Executes Spring Batch jobs as tasks  
- **Data Flow Dashboard** â€“ Web UI for monitoring and managing jobs  

## **ðŸ“Œ 2. Setting Up Spring Cloud Data Flow Locally**
ðŸ”¹ **Prerequisites**  
- Docker & Docker Compose  
- JDK 17+  
- Maven  

ðŸ”¹ **Start SCDF using Docker Compose**
```bash
curl -O https://raw.githubusercontent.com/spring-cloud/spring-cloud-dataflow/main/src/docker-compose/docker-compose.yml
docker-compose up
```
This starts **SCDF, Skipper, MySQL, and RabbitMQ/Kafka**.

ðŸ”¹ **Verify SCDF is Running**  
- Open **http://localhost:9393/dashboard** to access the UI  
- Test API:  
```bash
curl http://localhost:9393/about
```

## **ðŸ“Œ 3. Creating a Spring Batch Task for SCDF**
SCDF executes **batch jobs as tasks**, so first, we create a **Spring Batch Task**.  

ðŸ”¹ **Add Dependencies**
```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-task</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.batch</groupId>
    <artifactId>spring-batch-core</artifactId>
</dependency>
```

ðŸ”¹ **Define a Spring Batch Job**
```java
@EnableTask
@SpringBootApplication
public class BatchJobApplication {
    public static void main(String[] args) {
        SpringApplication.run(BatchJobApplication.class, args);
    }

    @Bean
    public Job sampleJob(JobBuilderFactory jobBuilderFactory, StepBuilderFactory stepBuilderFactory) {
        return jobBuilderFactory.get("sampleJob")
            .start(stepBuilderFactory.get("step1")
                .tasklet((stepContribution, chunkContext) -> {
                    System.out.println("Spring Batch Job Running...");
                    return RepeatStatus.FINISHED;
                })
                .build())
            .build();
    }
}
```

ðŸ”¹ **Package as a JAR**
```bash
mvn clean package
```

## **ðŸ“Œ 4. Deploying Spring Batch Job to SCDF**
### **1ï¸âƒ£ Register the Batch Job as a Task**
SCDF executes batch jobs as **tasks**, so we first register our batch job.  

```bash
dataflow:>app register --name batch-task --type task --uri file:///path/to/your-batch-job.jar
```
For Docker-based deployment:
```bash
dataflow:>app register --name batch-task --type task --uri docker://your-docker-image
```

### **2ï¸âƒ£ Create a Task Definition**
```bash
dataflow:>task create my-batch-task --definition "batch-task"
```

### **3ï¸âƒ£ Launch the Batch Task**
```bash
dataflow:>task launch my-batch-task
```

SCDF will execute the batch job and log its progress.

### **4ï¸âƒ£ Monitor the Job Execution**
- **UI:** Go to the **Tasks** tab in SCDF Dashboard  
- **API:** Fetch job execution status  
```bash
curl http://localhost:9393/tasks/executions
```

## **ðŸ“Œ 5. Scheduling & Orchestrating Batch Jobs**
### **ðŸ”¹ Scheduling Jobs in SCDF**
SCDF allows job scheduling using **Cron Expressions**.  

```bash
dataflow:>schedule create my-job-schedule --definition "my-batch-task" --expression "0 0 * * * *"
```
This schedules the batch job to run **every hour**.

### **ðŸ”¹ Managing Job Restart & Retries**
- Set **restartability** for failed jobs  
- Configure **retry logic** for steps in `application.properties`
```properties
spring.batch.job.enabled=false
spring.cloud.task.closecontext.enabled=false
```

## **ðŸ“Œ 6. Scaling Spring Batch Jobs in SCDF**
### **ðŸ”¹ Parallel Execution of Jobs**
SCDF can **scale jobs horizontally** by running multiple instances.  
Modify the launch command:
```bash
dataflow:>task launch my-batch-task --properties "spring.cloud.task.execution.platform.kubernetes"
```
This runs the job on Kubernetes.

### **ðŸ”¹ Partitioned Step Execution**
Use **Partitioner** to distribute work across multiple nodes.
```java
@Bean
public Step partitionedStep(StepBuilderFactory stepBuilderFactory, PartitionHandler partitionHandler) {
    return stepBuilderFactory.get("partitionedStep")
        .partitioner("workerStep", new ColumnRangePartitioner())
        .step(workerStep())
        .gridSize(4)
        .partitionHandler(partitionHandler)
        .build();
}
```

## **ðŸ“Œ 7. Monitoring & Logging Batch Jobs**
SCDF provides **real-time monitoring** of batch jobs.

### **ðŸ”¹ Enable Logging**
```properties
logging.level.org.springframework.cloud.task=DEBUG
```
Check logs via:
```bash
dataflow:>task execution log --id 1
```

### **ðŸ”¹ View Job Metrics in Grafana/Prometheus**
Enable **Micrometer Metrics** for monitoring.
```properties
management.metrics.export.prometheus.enabled=true
```
SCDF integrates with **Prometheus + Grafana** to visualize job performance.

## **ðŸ“Œ 8. Advanced Features**
### **ðŸ”¹ External Event Triggers (Kafka, RabbitMQ)**
SCDF can **trigger batch jobs based on events**.

Example: Trigger job when a Kafka message arrives.
```yaml
spring:
  cloud:
    stream:
      bindings:
        input:
          destination: batch-job-events
          group: batch
```

### **ðŸ”¹ Integration with Cloud Platforms**
- **Kubernetes** â€“ Deploy SCDF to **K8s** using Helm Charts  
- **AWS, Azure, GCP** â€“ Run SCDF batch jobs on cloud-native environments  
